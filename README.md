# ğŸ® Hangman AI Solver<div align="center"># Hangman AI Solver - HMM + Deep Reinforcement Learning



> **A hybrid approach combining Hidden Markov Models, Deep Reinforcement Learning, and Word Filtering**



## ğŸ‘¥ Team Members# ğŸ® Hangman AI Solver## Team Members



| Name | SRN |### *Combining Hidden Markov Models + Deep Reinforcement Learning*

|------|-----|

| Mohammed Musharraf | PES2UG23CS915 || Name | SRN |

| Mohammed Shehzaad Khan | PES2U23CS349 |

| Mohammed Bilal | PES2UG23CS344 |<br>|------|-----|

| Mohammed Aahil | PES2UG23CS342 |

| Mohammed Musharraf | PES2UG23CS915 |

---

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)| Mohammed Shehzaad Khan | PES2U23CS349 |

## ğŸ¯ Results

[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)| Mohammed Bilal | PES2UG23CS344 |

| Metric | Value |

|--------|-------|[![Success Rate](https://img.shields.io/badge/Success%20Rate-94.40%25-brightgreen.svg)](.)| Mohammed Aahil | PES2UG23CS342 |

| **Success Rate** | 94.40% (2000 test games) |

| **Avg Wrong Guesses** | 2.13 per game |[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](.)

| **Repeated Guesses** | 0 |

| **Training Win Rate** (Pure RL) | 7.18% |---

| **Testing Win Rate** (Hybrid) | 94.40% |

</div>

---

## ğŸ¯ Final Results

## ğŸ“ Project Structure

---

```

ML-Hackathon/- **Success Rate:** 94.40% on 2000 test games

â”œâ”€â”€ Data/

â”‚   â”œâ”€â”€ corpus.txt              # 50,000 training words## ğŸ‘¥ Team Members- **Average Wrong Guesses:** 2.13 per game

â”‚   â””â”€â”€ test.txt                # 2,000 test words

â”œâ”€â”€ Untitled14.ipynb            # Main implementation notebook- **Repeated Guesses:** 0

â”œâ”€â”€ Analysis_Report.md          # Detailed analysis report

â””â”€â”€ README.md                   # This file<div align="center">- **Training Win Rate (Pure RL):** 7.18%

```

- **Testing Win Rate (Hybrid System):** 94.40%

---

| Name | SRN |

## ğŸ—ï¸ System Architecture

|:----:|:---:|## ğŸ“ Project Structure

Our system uses a **three-part hybrid approach**:

| **Mohammed Musharraf** | PES2UG23CS915 |

### 1. ğŸ§  Hidden Markov Model (HMM)

- **States:** Position-based (0, 1, 2, ..., word_length-1)| **Mohammed Shehzaad Khan** | PES2U23CS349 |```

- **Emissions:** Letters (A-Z)

- **Models:** 24 separate HMMs for word lengths 1-24| **Mohammed Bilal** | PES2UG23CS344 |ML-Hackathon/

- **Smoothing:** Laplace smoothing (Î±=1.0)

- **Purpose:** Captures positional letter patterns in English words| **Mohammed Aahil** | PES2UG23CS342 |â”œâ”€â”€ Data/



### 2. ğŸ” Word Filtering Systemâ”‚   â”œâ”€â”€ corpus.txt           # 50,000 training words

- Matches current pattern against corpus words

- When â‰¤20 words match â†’ uses direct letter frequency</div>â”‚   â””â”€â”€ test.txt             # 2,000 test words

- **Most powerful component** of the system

- Provides highly accurate predictions for narrow search spacesâ”œâ”€â”€ Untitled14.ipynb         # Main implementation notebook



### 3. ğŸ¤– Deep Q-Network (DQN) Agent---â”œâ”€â”€ Analysis_Report.md       # Detailed analysis report



**State Representation (619 dimensions):**â””â”€â”€ README.md                # This file

- Masked word (540 dims): 20 positions Ã— 27 one-hot features

- Guessed letters (26 dims): Binary vector## ğŸ¯ Final Results```

- Lives remaining (1 dim): Normalized

- HMM probabilities (26 dims)

- Word filter probabilities (26 dims)

<div align="center">## ğŸ—ï¸ Architecture

**Network Architecture:**

```

Input (619) â†’ Dense (256) â†’ Dense (128) â†’ Dense (64) â†’ Output (26)

```| Metric | Value |### Three-Part System



**Training Configuration:**|:------:|:-----:|

- Experience replay buffer: 10,000 transitions

- Target network updates: Every 10 episodes| ğŸ† **Success Rate** | **94.40%** (2000 test games) |**1. Hidden Markov Model (HMM)**

- Exploration: Epsilon-greedy (1.0 â†’ 0.01)

| ğŸ“‰ **Avg Wrong Guesses** | **2.13** per game |- Position-based states (0, 1, 2, ..., word_length-1)

### âš¡ Hybrid Strategy

| ğŸ² **Repeated Guesses** | **0** |- Letter emissions (A-Z)

```python

if matching_words <= 20:| ğŸ”„ **Training Win Rate** (Pure RL) | 7.18% |- 24 separate HMMs for word lengths 1-24

    return word_filter_prediction()

else:| âœ¨ **Testing Win Rate** (Hybrid) | **94.40%** |- Laplace smoothing (Î±=1.0) for unseen patterns

    return blend(

        word_filtering=50%,- Captures positional letter patterns in English

        hmm_predictions=30%,

        dqn_q_values=20%</div>

    )

```**2. Word Filtering System**



------- Matches current pattern with corpus words



## ğŸš€ Quick Start- When â‰¤20 words match, uses direct letter frequency



### Installation## ğŸ“ Project Structure- Most powerful component of the system



```bash- Provides accurate predictions for narrow search spaces

pip install torch tqdm matplotlib numpy

``````



### Data PreparationML-Hackathon/**3. Deep Q-Network (DQN) Agent**



Place your data files in the `Data/` directory:â”‚- State representation: 619 dimensions

- `corpus.txt` - 50,000 training words

- `test.txt` - 2,000 test wordsâ”œâ”€â”€ ğŸ“‚ Data/  - Masked word (540 dims): 20 positions Ã— 27 one-hot features



### Running the Notebookâ”‚   â”œâ”€â”€ corpus.txt              # 50,000 training words  - Guessed letters (26 dims): Binary vector



The notebook `Untitled14.ipynb` contains three parts:â”‚   â””â”€â”€ test.txt                # 2,000 test words  - Lives remaining (1 dim): Normalized



**Part 1: HMM Training** (~1 minute)â”‚  - HMM probabilities (26 dims)

- Loads and preprocesses corpus

- Trains 24 HMMs (one per word length)â”œâ”€â”€ ğŸ““ Untitled14.ipynb         # Main implementation notebook  - Word filter probabilities (26 dims)

- Creates word matcher for filtering

- Saves: `hangman_models.pkl`, `word_matcher.pkl`â”œâ”€â”€ ğŸ“„ Analysis_Report.md       # Detailed analysis report- Network architecture: 619 â†’ 256 â†’ 128 â†’ 64 â†’ 26



**Part 2: RL Agent Training** (~19 minutes on GPU)â””â”€â”€ ğŸ“– README.md                # This file- Experience replay buffer: 10,000 transitions

- Loads trained HMMs

- Creates Hangman environment```- Target network updated every 10 episodes

- Trains DQN agent for 5000 episodes

- Saves: `dqn_agent.pth`- Epsilon-greedy exploration: 1.0 â†’ 0.01



**Part 3: Evaluation** (~2 minutes)---

- Loads all models

- Creates hybrid agent**Hybrid Strategy**

- Evaluates on 2000 test words

- Saves: `evaluation_results.pkl`, visualizations## ğŸ—ï¸ System Architecture- If matching words â‰¤ 20: Use word filter directly



### Expected Output- Otherwise: Blend all sources



```<div align="center">  - 50% word filtering

HANGMAN HMM TRAINING

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  - 30% HMM predictions

Loaded 50000 words

Training HMMs for each word length...### **Three-Part Hybrid System**  - 20% DQN Q-values

âœ… HMM Training Complete!



HANGMAN RL TRAINING

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</div>## ğŸš€ Quick Start

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000

Final Win Rate: 7.18%

âœ… Training Complete!

<br>### Setup

HANGMAN EVALUATION

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Evaluating Hybrid Agent: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000

Success Rate: 94.40%### ğŸ§  **1. Hidden Markov Model (HMM)**1. **Install dependencies:**

âœ… Evaluation Complete!

``````bash



---> Captures positional letter patterns in English wordspip install torch tqdm matplotlib numpy pickle



## ğŸ“Š Key Findings```



### âœ… What Worked- **States:** Position-based (0, 1, 2, ..., word_length-1)



- **Hybrid approach dominated** - 94.40% vs 7.18% for pure RL- **Emissions:** Letters (A-Z)2. **Prepare data files:**

- **Word filtering was critical** - Direct corpus matching provided strongest signal

- **HMM captured patterns** - Position-specific letter probabilities worked well- **Models:** 24 separate HMMs for word lengths 1-24- Place `corpus.txt` in root directory (50,000 words)



### âŒ What Didn't Work- **Smoothing:** Laplace smoothing (Î±=1.0) for unseen patterns- Place `test_words.txt` in root directory (2,000 words)



- **Pure RL struggled** - 619-dimensional state space made learning difficult- **Purpose:** Learn where letters typically appear in words

- **Sparse rewards** - Mostly negative feedback hindered learning

- **Conservative exploration** - 700 episodes to reach minimum epsilon was too slow### Running the Notebook



---<br>



## ğŸ¯ Reward FunctionThe notebook `Untitled14.ipynb` contains three main parts:



| Action | Reward |### ğŸ” **2. Word Filtering System**

|--------|--------|

| Correct guess | +10 per position revealed |**Part 1: HMM Training**

| Win game | +100 bonus |

| Wrong guess | -15 penalty |> Direct pattern matching with corpus- Loads and preprocesses corpus

| Lose game | -100 penalty |

| Repeated guess | -20 efficiency penalty |- Trains 24 HMMs (one per word length)



---- Matches current pattern against corpus words- Creates word matcher for filtering



## ğŸ“ˆ Performance by Word Length- When â‰¤20 words match â†’ uses direct letter frequency- Saves models: `hangman_models.pkl`, `word_matcher.pkl`



| Word Length | Win Rate | Context |- **Most powerful component** of the system- Training time: ~1 minute

|-------------|----------|---------|

| 2-4 letters | 50-80% | Limited context |- Provides highly accurate predictions for narrow search spaces

| 5-9 letters | 95%+ | Optimal range |

| 10-15 letters | 95%+ | Many clues |**Part 2: RL Agent Training**

| 16+ letters | ~100% | Extensive context |

<br>- Loads trained HMMs

---

- Creates Hangman environment

## ğŸ”§ Training Parameters

### ğŸ¤– **3. Deep Q-Network (DQN) Agent**- Trains DQN agent for 5000 episodes

| Parameter | Value |

|-----------|-------|- Saves model: `dqn_agent.pth`

| Episodes | 5000 |

| Batch Size | 64 |> Reinforcement learning for strategic decision-making- Training time: ~19 minutes on GPU

| Learning Rate | 0.001 |

| Gamma (Discount) | 0.95 |

| Epsilon Start | 1.0 |

| Epsilon Min | 0.01 |**State Representation (619 dimensions):****Part 3: Evaluation**

| Epsilon Decay | 0.995 |

| Replay Buffer | 10,000 |- ğŸ¯ Masked word (540 dims): 20 positions Ã— 27 one-hot features- Loads all models

| Target Update | Every 10 episodes |

- âœ… Guessed letters (26 dims): Binary vector- Creates hybrid agent

---

- â¤ï¸ Lives remaining (1 dim): Normalized- Evaluates on 2000 test words

## ğŸ“ Generated Files

- ğŸ“Š HMM probabilities (26 dims)- Generates visualizations

- `hangman_models.pkl` - Trained HMM models for all word lengths

- `word_matcher.pkl` - Word filtering system- ğŸ“ˆ Word filter probabilities (26 dims)- Saves results: `evaluation_results.pkl`

- `dqn_agent.pth` - Trained DQN agent weights

- `training_results.png` - Training curves visualization- Evaluation time: ~2 minutes

- `evaluation_results.pkl` - Evaluation statistics

- `evaluation_results.png` - Evaluation visualizations**Neural Network:**



---```### Expected Output



## ğŸ’¡ Key Lessons619 â†’ 256 â†’ 128 â†’ 64 â†’ 26



1. **Domain knowledge beats pure learning** - Explicit word matching outperformed neural networks``````

2. **System design matters** - Intelligent combination of techniques > any single method

3. **RL as refinement** - Use RL to handle edge cases, not learn entire strategyHANGMAN HMM TRAINING

4. **Simple can be better** - Word filtering was simpler AND more effective than complex neural networks

**Training Features:**Loaded 50000 words

---

- Experience replay buffer: 10,000 transitionsTraining HMMs for each word length...

## ğŸ“š References

- Target network updates: Every 10 episodesâœ… HMM Training Complete!

- Hidden Markov Models for sequence prediction

- Deep Q-Networks (DQN) for reinforcement learning- Exploration: Epsilon-greedy (1.0 â†’ 0.01)

- Experience replay and target networks for stable learning

- Epsilon-greedy exploration strategyHANGMAN RL TRAINING



---<br>Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000



**PES University - Machine Learning Hackathon 2025**  Final Win Rate: 7.18%

*November 3, 2025*

### âš¡ **Hybrid Strategy**âœ… Training Complete!



```pythonHANGMAN EVALUATION

if matching_words <= 20:Evaluating Hybrid Agent: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000

    return word_filter_prediction()Success Rate: 94.40%

else:âœ… Evaluation Complete!

    return blend(```

        word_filtering=50%,

        hmm_predictions=30%,## ğŸ“Š Key Findings

        dqn_q_values=20%

    )### What Worked

```

âœ… **Hybrid approach dominated** - Combining word filtering, HMM, and RL achieved 94.40% vs 7.18% for pure RL

---

âœ… **Word filtering was critical** - Direct corpus matching provided the strongest signal

## ğŸš€ Quick Start Guide

âœ… **HMM captured language patterns** - Position-specific letter probabilities worked well

### ğŸ“¦ **Installation**

### What Didn't Work

```bash

pip install torch tqdm matplotlib numpyâŒ **Pure RL struggled** - 619-dimensional state space made learning difficult

```

âŒ **Sparse rewards** - Mostly negative feedback hindered learning

### ğŸ“‚ **Data Preparation**

âŒ **Too conservative exploration** - 700 episodes to reach minimum epsilon was too slow

Place your data files in the `Data/` directory:

- `corpus.txt` - 50,000 training words## ğŸ¯ Reward Function

- `test.txt` - 2,000 test words

- **Correct guess:** +10 per position revealed + 100 if won

### â–¶ï¸ **Running the Notebook**- **Wrong guess:** -15 (+ -100 if lost)

- **Repeated guess:** -20 (heavy efficiency penalty)

The notebook `Untitled14.ipynb` has three main sections:

## ï¿½ Performance by Word Length

<br>

- **Short words (2-4 letters):** ~50-80% win rate (limited context)

#### **Part 1: ğŸ§  HMM Training** (~1 minute)- **Medium words (5-9 letters):** ~95%+ win rate (optimal)

- Loads and preprocesses corpus- **Long words (10-15 letters):** ~95%+ win rate (many clues)

- Trains 24 HMMs (one per word length)- **Very long words (16+ letters):** ~100% win rate (extensive context)

- Creates word matcher for filtering

- **Saves:** `hangman_models.pkl`, `word_matcher.pkl`## ğŸ”§ Training Parameters



#### **Part 2: ğŸ¤– RL Agent Training** (~19 minutes on GPU)| Parameter | Value |

- Loads trained HMMs|-----------|-------|

- Creates Hangman environment| Episodes | 5000 |

- Trains DQN agent for 5000 episodes| Batch Size | 64 |

- **Saves:** `dqn_agent.pth`| Learning Rate | 0.001 |

| Gamma (Discount) | 0.95 |

#### **Part 3: ğŸ“Š Evaluation** (~2 minutes)| Epsilon Start | 1.0 |

- Loads all models| Epsilon Min | 0.01 |

- Creates hybrid agent| Epsilon Decay | 0.995 |

- Evaluates on 2000 test words| Replay Buffer | 10,000 |

- **Saves:** `evaluation_results.pkl`, visualizations| Target Update | Every 10 episodes |



<br>## ğŸ“ Files Generated



### ğŸ“º **Expected Output**- `hangman_models.pkl` - Trained HMM models for all word lengths

- `word_matcher.pkl` - Word filtering system

```- `dqn_agent.pth` - Trained DQN agent weights

ğŸ§  HANGMAN HMM TRAINING- `training_results.png` - Training curves visualization

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”- `evaluation_results.pkl` - Evaluation statistics

Loaded 50000 words- `evaluation_results.png` - Evaluation visualizations

Training HMMs for each word length...

âœ… HMM Training Complete!## ï¿½ Key Lessons



ğŸ¤– HANGMAN RL TRAINING1. **Domain knowledge beats pure learning** - Explicit word matching outperformed neural networks

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”2. **System design matters** - Intelligent combination of techniques is more powerful than any single method

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/50003. **RL as refinement** - Use RL to handle edge cases, not learn entire strategy from scratch

Final Win Rate: 7.18%4. **Simple can be better** - Word filtering was simpler and more effective than complex neural networks

âœ… Training Complete!

## ï¿½ References

ğŸ“Š HANGMAN EVALUATION

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”- Hidden Markov Models for sequence prediction

Evaluating Hybrid Agent: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000- Deep Q-Networks (DQN) for reinforcement learning

Success Rate: 94.40%- Experience replay and target networks for stable learning

âœ… Evaluation Complete!- Epsilon-greedy exploration strategy

```

---

---

**PES University - Machine Learning Hackathon 2025**  

## ğŸ“Š Key Findings**Date:** November 3, 2025


<table>
<tr>
<td width="50%">

### âœ… **What Worked**

- **ğŸ† Hybrid approach dominated**  
  94.40% vs 7.18% for pure RL

- **ğŸ” Word filtering was critical**  
  Direct corpus matching = strongest signal

- **ğŸ§  HMM captured patterns**  
  Position-specific letter probabilities

</td>
<td width="50%">

### âŒ **What Didn't Work**

- **ğŸ¤– Pure RL struggled**  
  619-dimensional state space too complex

- **âš ï¸ Sparse rewards**  
  Mostly negative feedback hindered learning

- **ğŸŒ Conservative exploration**  
  700 episodes to reach min epsilon

</td>
</tr>
</table>

---

## ğŸ¯ Reward Function

| Action | Reward |
|:-------|:------:|
| âœ… Correct guess | **+10** per position revealed |
| ğŸŠ Win game | **+100** bonus |
| âŒ Wrong guess | **-15** penalty |
| ğŸ’€ Lose game | **-100** penalty |
| ğŸ” Repeated guess | **-20** efficiency penalty |

---

## ğŸ“ˆ Performance by Word Length

<div align="center">

| Word Length | Win Rate | Context Level |
|:-----------:|:--------:|:-------------:|
| 2-4 letters | 50-80% | âš ï¸ Limited |
| 5-9 letters | **95%+** | âœ… Optimal |
| 10-15 letters | **95%+** | âœ… Many clues |
| 16+ letters | **~100%** | ğŸ¯ Extensive |

</div>

---

## ğŸ”§ Training Parameters

<div align="center">

| Parameter | Value |
|:---------:|:-----:|
| ğŸ”„ **Episodes** | 5000 |
| ğŸ“¦ **Batch Size** | 64 |
| ğŸ“š **Learning Rate** | 0.001 |
| ğŸ’° **Gamma (Discount)** | 0.95 |
| ğŸ² **Epsilon Start** | 1.0 |
| ğŸ¯ **Epsilon Min** | 0.01 |
| ğŸ“‰ **Epsilon Decay** | 0.995 |
| ğŸ’¾ **Replay Buffer** | 10,000 |
| ğŸ”„ **Target Update** | Every 10 episodes |

</div>

---

## ğŸ“ Generated Files

| File | Description |
|:-----|:------------|
| ğŸ§  `hangman_models.pkl` | Trained HMM models for all word lengths |
| ğŸ” `word_matcher.pkl` | Word filtering system |
| ğŸ¤– `dqn_agent.pth` | Trained DQN agent weights |
| ğŸ“Š `training_results.png` | Training curves visualization |
| ğŸ“ˆ `evaluation_results.pkl` | Evaluation statistics |
| ğŸ¨ `evaluation_results.png` | Evaluation visualizations |

---

## ğŸ’¡ Key Lessons Learned

<div align="center">

### ğŸŒŸ **Four Core Insights**

</div>

<br>

> **1. ğŸ§  Domain knowledge beats pure learning**  
> Explicit word matching outperformed neural networks

> **2. ğŸ—ï¸ System design matters**  
> Intelligent combination > any single method

> **3. âš¡ RL as refinement**  
> Use RL for edge cases, not learning entire strategy

> **4. âœ¨ Simple can be better**  
> Word filtering was simpler AND more effective

---

## ğŸ“š References

- ğŸ§  Hidden Markov Models for sequence prediction
- ğŸ¤– Deep Q-Networks (DQN) for reinforcement learning
- ğŸ’¾ Experience replay and target networks
- ğŸ² Epsilon-greedy exploration strategy

---

<div align="center">

### ğŸ“ **PES University**
**Machine Learning Hackathon 2025**

*Date: November 3, 2025*

<br>

**Made with â¤ï¸ by Team Mohammed**

</div>
