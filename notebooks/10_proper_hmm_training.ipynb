{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0cdf61",
   "metadata": {},
   "source": [
    "# Proper HMM Training from Scratch\n",
    "\n",
    "**Goal:** Train a PROPER HMM that gives good letter predictions\n",
    "\n",
    "Key insight: Test words are NOT in corpus, so we need to learn PATTERNS, not memorize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db77bb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 words from corpus\n",
      "Sample: ['suburbanize', 'asmack', 'hypotypic', 'promoderationist', 'consonantly']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load corpus\n",
    "with open('../Data/corpus.txt', 'r', encoding='utf-8') as f:\n",
    "    corpus_words = [line.strip().lower() for line in f if line.strip()]\n",
    "\n",
    "# Clean words\n",
    "corpus_words = [''.join(c for c in word if c.isalpha()) for word in corpus_words]\n",
    "corpus_words = [w for w in corpus_words if len(w) > 0]\n",
    "\n",
    "print(f\"Loaded {len(corpus_words)} words from corpus\")\n",
    "print(f\"Sample: {corpus_words[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb1f8d",
   "metadata": {},
   "source": [
    "## Build Better HMM Model\n",
    "\n",
    "Focus on what actually helps:\n",
    "1. Global letter frequency (for first guesses)\n",
    "2. Bigrams (letter pairs)\n",
    "3. Position-based frequency\n",
    "4. Pattern-based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d853e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ImprovedHMM class defined\n"
     ]
    }
   ],
   "source": [
    "class ImprovedHMM:\n",
    "    def __init__(self):\n",
    "        self.alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        \n",
    "        # Global letter frequency\n",
    "        self.global_freq = Counter()\n",
    "        \n",
    "        # Bigrams: char1 -> char2 -> count\n",
    "        self.bigrams = defaultdict(Counter)\n",
    "        \n",
    "        # Position frequencies (first 20 positions)\n",
    "        self.position_freq = defaultdict(Counter)\n",
    "        \n",
    "        # Letter patterns by word length\n",
    "        self.length_patterns = defaultdict(Counter)\n",
    "    \n",
    "    def train(self, words):\n",
    "        print(\"Training Improved HMM...\")\n",
    "        \n",
    "        for word in tqdm(words, desc=\"Processing words\"):\n",
    "            # Global frequency\n",
    "            for char in word:\n",
    "                self.global_freq[char] += 1\n",
    "            \n",
    "            # Bigrams\n",
    "            for i in range(len(word) - 1):\n",
    "                self.bigrams[word[i]][word[i+1]] += 1\n",
    "            \n",
    "            # Position frequency\n",
    "            for i, char in enumerate(word):\n",
    "                if i < 20:\n",
    "                    self.position_freq[i][char] += 1\n",
    "            \n",
    "            # Length patterns\n",
    "            length = len(word)\n",
    "            for char in set(word):\n",
    "                self.length_patterns[length][char] += 1\n",
    "        \n",
    "        # Normalize global frequency\n",
    "        total = sum(self.global_freq.values())\n",
    "        self.global_freq = {c: count/total for c, count in self.global_freq.items()}\n",
    "        \n",
    "        print(f\"✓ Training complete\")\n",
    "        print(f\"  Top letters: {sorted(self.global_freq.items(), key=lambda x: -x[1])[:10]}\")\n",
    "    \n",
    "    def predict_letter_probabilities(self, masked_word, guessed_letters, word_length):\n",
    "        \"\"\"Predict letter probabilities for current state.\"\"\"\n",
    "        probs = {c: 0.0 for c in self.alphabet}\n",
    "        \n",
    "        # Strategy 1: Use global frequency (baseline)\n",
    "        for char in self.alphabet:\n",
    "            if char not in guessed_letters:\n",
    "                probs[char] += self.global_freq.get(char, 0.0) * 1.0\n",
    "        \n",
    "        # Strategy 2: Use bigrams from revealed letters\n",
    "        for i, char in enumerate(masked_word):\n",
    "            if char is not None:\n",
    "                # Look ahead\n",
    "                if i + 1 < len(masked_word) and masked_word[i+1] is None:\n",
    "                    if char in self.bigrams:\n",
    "                        total = sum(self.bigrams[char].values())\n",
    "                        if total > 0:\n",
    "                            for next_char, count in self.bigrams[char].items():\n",
    "                                if next_char not in guessed_letters:\n",
    "                                    probs[next_char] += (count / total) * 2.0\n",
    "                \n",
    "                # Look behind\n",
    "                if i > 0 and masked_word[i-1] is None:\n",
    "                    for prev_char in self.alphabet:\n",
    "                        if prev_char not in guessed_letters and prev_char in self.bigrams:\n",
    "                            if char in self.bigrams[prev_char]:\n",
    "                                count = self.bigrams[prev_char][char]\n",
    "                                total = sum(self.bigrams[prev_char].values())\n",
    "                                if total > 0:\n",
    "                                    probs[prev_char] += (count / total) * 2.0\n",
    "        \n",
    "        # Strategy 3: Position-based frequency for blank positions\n",
    "        for i, char in enumerate(masked_word):\n",
    "            if char is None and i < 20:\n",
    "                if i in self.position_freq:\n",
    "                    total = sum(self.position_freq[i].values())\n",
    "                    if total > 0:\n",
    "                        for c, count in self.position_freq[i].items():\n",
    "                            if c not in guessed_letters:\n",
    "                                probs[c] += (count / total) * 1.5\n",
    "        \n",
    "        # Strategy 4: Length-based patterns\n",
    "        if word_length in self.length_patterns:\n",
    "            total = sum(self.length_patterns[word_length].values())\n",
    "            if total > 0:\n",
    "                for c, count in self.length_patterns[word_length].items():\n",
    "                    if c not in guessed_letters:\n",
    "                        probs[c] += (count / total) * 0.5\n",
    "        \n",
    "        # Normalize\n",
    "        total = sum(probs.values())\n",
    "        if total > 0:\n",
    "            probs = {c: p/total for c, p in probs.items()}\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def save(self, filepath):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        print(f\"✓ Model saved to {filepath}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "print(\"✓ ImprovedHMM class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec2772bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Improved HMM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing words: 100%|██████████| 50000/50000 [00:00<00:00, 179770.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training complete\n",
      "  Top letters: [('e', 0.10366177251017158), ('a', 0.0886802624817838), ('i', 0.088591813870427), ('o', 0.0754529832453059), ('r', 0.07079890155248372), ('n', 0.0701565961604879), ('t', 0.06779164876635246), ('s', 0.061164320672546395), ('l', 0.057714824829631126), ('c', 0.04573635574873856)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the improved HMM\n",
    "hmm = ImprovedHMM()\n",
    "hmm.train(corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639c59d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HMM predictions:\n",
      "\n",
      "Empty 5-letter word:\n",
      "  Top 5: [('e', 0.0944451971757346), ('a', 0.0901352794680006), ('o', 0.07865477524185965), ('r', 0.07671637486089959), ('i', 0.07334579624967802)]\n",
      "\n",
      "Word: _e___\n",
      "  Top 5: [('r', 0.07881948412134224), ('v', 0.06761419297406523), ('t', 0.06269464086398246), ('n', 0.05917035749228527), ('l', 0.055121413538864183)]\n",
      "\n",
      "Word: ___ing\n",
      "  Top 5: [('t', 0.07404734518306579), ('r', 0.07216262892429859), ('l', 0.06139897668415388), ('d', 0.060572843365315675), ('a', 0.05679379676741129)]\n"
     ]
    }
   ],
   "source": [
    "# Test on a sample\n",
    "print(\"Testing HMM predictions:\\n\")\n",
    "\n",
    "# Test 1: Empty word\n",
    "probs = hmm.predict_letter_probabilities([None]*5, set(), 5)\n",
    "top = sorted(probs.items(), key=lambda x: -x[1])[:5]\n",
    "print(f\"Empty 5-letter word:\")\n",
    "print(f\"  Top 5: {top}\\n\")\n",
    "\n",
    "# Test 2: With 'e' revealed\n",
    "masked = [None, 'e', None, None, None]\n",
    "probs = hmm.predict_letter_probabilities(masked, {'e'}, 5)\n",
    "top = sorted(probs.items(), key=lambda x: -x[1])[:5]\n",
    "print(f\"Word: _e___\")\n",
    "print(f\"  Top 5: {top}\\n\")\n",
    "\n",
    "# Test 3: With 'ing' ending\n",
    "masked = [None, None, None, 'i', 'n', 'g']\n",
    "probs = hmm.predict_letter_probabilities(masked, {'i', 'n', 'g'}, 6)\n",
    "top = sorted(probs.items(), key=lambda x: -x[1])[:5]\n",
    "print(f\"Word: ___ing\")\n",
    "print(f\"  Top 5: {top}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d4cb98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING IMPROVED HMM (500 words)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing HMM: 100%|██████████| 500/500 [00:00<00:00, 1937.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Win Rate: 0.2260 (22.60%)\n",
      "Wrong Guesses: 2737 (avg: 5.47)\n",
      "Repeated: 0\n",
      "Score: -13572.00\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Quick evaluation on test set\n",
    "from hangman_env import HangmanEnv\n",
    "from utils import calculate_final_score\n",
    "\n",
    "# Load test words\n",
    "with open('../Data/test.txt', 'r') as f:\n",
    "    test_words = [''.join(c for c in line.strip().lower() if c.isalpha()) for line in f if line.strip()][:500]\n",
    "\n",
    "def test_hmm(hmm, test_words):\n",
    "    results = []\n",
    "    for word in tqdm(test_words, desc=\"Testing HMM\"):\n",
    "        env = HangmanEnv(word, max_lives=6)\n",
    "        env.reset()\n",
    "        \n",
    "        while not env.done:\n",
    "            masked = env.get_masked_word_list()\n",
    "            probs = hmm.predict_letter_probabilities(masked, env.guessed_letters, len(word))\n",
    "            \n",
    "            # Pick best available letter\n",
    "            available = {k: v for k, v in probs.items() if k not in env.guessed_letters}\n",
    "            if available:\n",
    "                action = max(available, key=available.get)\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "            env.step(action)\n",
    "        \n",
    "        stats = env.get_stats()\n",
    "        results.append({'won': env.won, 'wrong': stats['wrong_count'], 'repeated': stats['repeated_count']})\n",
    "    \n",
    "    wins = sum(1 for r in results if r['won'])\n",
    "    rate = wins / len(results)\n",
    "    wrong = sum(r['wrong'] for r in results)\n",
    "    repeated = sum(r['repeated'] for r in results)\n",
    "    score = calculate_final_score(rate, wrong, repeated, len(results))\n",
    "    \n",
    "    return rate, score, wrong, repeated\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING IMPROVED HMM (500 words)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rate, score, wrong, repeated = test_hmm(hmm, test_words)\n",
    "\n",
    "print(f\"\\nWin Rate: {rate:.4f} ({rate*100:.2f}%)\")\n",
    "print(f\"Wrong Guesses: {wrong} (avg: {wrong/len(test_words):.2f})\")\n",
    "print(f\"Repeated: {repeated}\")\n",
    "print(f\"Score: {score:.2f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be554ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model saved to ../models/improved_hmm.pkl\n",
      "\n",
      "✅ Improved HMM saved and ready for RL training!\n"
     ]
    }
   ],
   "source": [
    "# Save the improved HMM\n",
    "hmm.save('../models/improved_hmm.pkl')\n",
    "print(\"\\n✅ Improved HMM saved and ready for RL training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
