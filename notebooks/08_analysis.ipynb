{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analysis and Visualization\n",
        "\n",
        "This notebook creates visualizations and prepares data for the analysis report.\n",
        "\n",
        "Includes:\n",
        "- Learning curves from training\n",
        "- Evaluation metrics\n",
        "- Performance analysis\n",
        "- Comparison with baseline (HMM-only agent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Load results\n",
        "with open('../results/training_history.pkl', 'rb') as f:\n",
        "    training_history = pickle.load(f)\n",
        "\n",
        "with open('../results/evaluation_results.pkl', 'rb') as f:\n",
        "    evaluation_results = pickle.load(f)\n",
        "\n",
        "print(\"Results loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "print(\"=\" * 60)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Success Rate: {evaluation_results['success_rate']:.4f} ({evaluation_results['success_rate']*100:.2f}%)\")\n",
        "print(f\"Total Wrong Guesses: {evaluation_results['total_wrong_guesses']}\")\n",
        "print(f\"Total Repeated Guesses: {evaluation_results['total_repeated_guesses']}\")\n",
        "print(f\"Final Score: {evaluation_results['final_score']:.2f}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive visualization\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "\n",
        "# 1. Training: Win Rate\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "window = 100\n",
        "if len(training_history['episode_wins']) >= window:\n",
        "    wins_array = np.array(training_history['episode_wins'])\n",
        "    moving_avg = np.convolve(wins_array, np.ones(window)/window, mode='valid')\n",
        "    ax1.plot(range(window-1, len(wins_array)), moving_avg, linewidth=2)\n",
        "    ax1.set_title('Training: Win Rate Over Time', fontsize=12, fontweight='bold')\n",
        "    ax1.set_xlabel('Episode')\n",
        "    ax1.set_ylabel('Win Rate')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Training: Episode Rewards\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "rewards_array = np.array(training_history['episode_rewards'])\n",
        "moving_avg_rewards = np.convolve(rewards_array, np.ones(window)/window, mode='valid')\n",
        "ax2.plot(range(window-1, len(rewards_array)), moving_avg_rewards, linewidth=2, color='green')\n",
        "ax2.set_title('Training: Episode Rewards', fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel('Episode')\n",
        "ax2.set_ylabel('Average Reward')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Training: Wrong Guesses\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "wrong_array = np.array(training_history['episode_wrong_guesses'])\n",
        "moving_avg_wrong = np.convolve(wrong_array, np.ones(window)/window, mode='valid')\n",
        "ax3.plot(range(window-1, len(wrong_array)), moving_avg_wrong, linewidth=2, color='red')\n",
        "ax3.set_title('Training: Wrong Guesses Over Time', fontsize=12, fontweight='bold')\n",
        "ax3.set_xlabel('Episode')\n",
        "ax3.set_ylabel('Average Wrong Guesses')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Epsilon Decay\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "ax4.plot(training_history['epsilon_values'], linewidth=2, color='purple')\n",
        "ax4.set_title('Exploration Rate (Epsilon) Decay', fontsize=12, fontweight='bold')\n",
        "ax4.set_xlabel('Episode')\n",
        "ax4.set_ylabel('Epsilon')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Evaluation Progress\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "if training_history['eval_win_rates']:\n",
        "    eval_episodes = [500 * (i+1) for i in range(len(training_history['eval_win_rates']))]\n",
        "    ax5.plot(eval_episodes, training_history['eval_win_rates'], marker='o', linewidth=2, markersize=8)\n",
        "    ax5.set_title('Evaluation Win Rate During Training', fontsize=12, fontweight='bold')\n",
        "    ax5.set_xlabel('Training Episode')\n",
        "    ax5.set_ylabel('Win Rate')\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Final Evaluation Metrics\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "metrics = ['Success\\nRate', 'Wrong\\nGuesses\\n(per game)', 'Repeated\\nGuesses\\n(per game)']\n",
        "values = [\n",
        "    evaluation_results['success_rate'],\n",
        "    evaluation_results['total_wrong_guesses'] / evaluation_results['num_games'],\n",
        "    evaluation_results['total_repeated_guesses'] / evaluation_results['num_games']\n",
        "]\n",
        "bars = ax6.bar(metrics, values, color=['green', 'red', 'orange'], alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "ax6.set_title('Final Evaluation Metrics', fontsize=12, fontweight='bold')\n",
        "ax6.set_ylabel('Value')\n",
        "ax6.grid(True, alpha=0.3, axis='y')\n",
        "# Add value labels on bars\n",
        "for bar, val in zip(bars, values):\n",
        "    height = bar.get_height()\n",
        "    ax6.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{val:.3f}',\n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/comprehensive_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Comprehensive visualization saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance by word length\n",
        "detailed_results = evaluation_results['detailed_results']\n",
        "df = pd.DataFrame(detailed_results)\n",
        "df['word_length'] = df['word'].apply(len)\n",
        "\n",
        "# Group by word length\n",
        "length_stats = df.groupby('word_length').agg({\n",
        "    'won': ['sum', 'count', 'mean'],\n",
        "    'wrong_guesses': 'mean',\n",
        "    'repeated_guesses': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "print(\"\\nPerformance by Word Length:\")\n",
        "print(\"=\" * 80)\n",
        "print(length_stats)\n",
        "\n",
        "# Visualize performance by word length\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Win rate by length\n",
        "length_win_rate = df.groupby('word_length')['won'].mean()\n",
        "axes[0].bar(length_win_rate.index, length_win_rate.values, alpha=0.7, edgecolor='black')\n",
        "axes[0].set_title('Win Rate by Word Length', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('Word Length')\n",
        "axes[0].set_ylabel('Win Rate')\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Average wrong guesses by length\n",
        "length_wrong = df.groupby('word_length')['wrong_guesses'].mean()\n",
        "axes[1].bar(length_wrong.index, length_wrong.values, alpha=0.7, color='red', edgecolor='black')\n",
        "axes[1].set_title('Average Wrong Guesses by Word Length', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('Word Length')\n",
        "axes[1].set_ylabel('Average Wrong Guesses')\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/performance_by_length.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Performance by length visualization saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate Analysis Report PDF\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from generate_report import generate_report\n",
        "\n",
        "print(\"Generating Analysis Report PDF...\")\n",
        "try:\n",
        "    generate_report()\n",
        "    print(\"✓ Analysis Report PDF generated successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error generating PDF: {e}\")\n",
        "    print(\"Note: You may need to install reportlab: pip install reportlab\")\n",
        "    print(\"Alternatively, you can create the PDF manually using the information above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
